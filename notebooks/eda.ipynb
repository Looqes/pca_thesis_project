{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Information\n",
    "Name: **Lucas Belderink**\n",
    "\n",
    "StudentID: **12151750**\n",
    "\n",
    "Email: [**lucas.belderink@student.uva.nl**](lucas.belderink@student.uva.nl)\n",
    "\n",
    "Submitted on: **22.3.2024**\n",
    "\n",
    "github link: [**https://github.com/Looqes/pca_thesis_project**](https://github.com/Looqes/pca_thesis_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Context\n",
    "\n",
    "The data used in this project consists of sets of images for 170 different patients, acquired from different scanners at different times. The data belongs to the NKI and is aquired from past patients. The images come in the form of .nii files, a common format for multidimensional medical imaging data and are 3-dimensional, thus layered. Also added to the data are .nrrd delineation files which carry the tumor delineations. These are made by pathology within the NKI following radical prostatectomies (in which the prostate is removed). Finally, a folder is included containing tumor delineations made by expert radiologists based on their interpretation of MRI's. These will be used at a later time however as the main focus lies on just using the mri's to train a model to make delineations. For now these will not be loaded and/or used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "For each patient the relevant data (at least at this moment) consists of the following:\n",
    "+ axial-plane T2 scan\n",
    "+ A Diffusion Weighted Imaging (DWI) Apparent Diffusion Coefficient (ADC) map\n",
    "+ A DWI Perfusion map\n",
    "\n",
    "The axial plane T2 scan is relevant because the other images are also in the axial plane, and the objective is to match and overlap them to then feed them to the model. A python package called nibabel is used to open them & gather their image data as numerical arrays, and other metadata. The first goal is to see how the resolutions of the images vary across patients, as it is apparent beforehand by manual inspection that they vary slightly between patients. To use the data with the model the image have to be resized to a common resultion per patient. The resolution between patients does not have to be the same necessarily as the model planned to be used (nnUnet) does some preprocessing automatically and will take care of this. \\\n",
    "\n",
    "For the delineations, for every patient, a number of .nrrd files is included containing the delineations mapped to the T2 axial scans. When these are opened in conjunction using visualization software in the form of Slicer they overlap and create information about the position and presence of a tumor. They are mapped specifically to the T2 scans for the patients and thus share their resolution. Not all slices of a patient that does actually have a tumor contain delineations however, as the tumor usually does not span the entire prostate. Thus the set of slices that have mapped tumor delineations, in case of the presence of a tumor, is always a subset of the total amount of slices in a patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\"../scripts\" not in sys.path and sys.path.insert(0, '../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "# import os\n",
    "from os import listdir\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "# import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nb\n",
    "\n",
    "# Custom objects included in scripts\n",
    "import patient\n",
    "import read_scans_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The amount of patients available\n",
    "img_folders = [f for f in listdir(\"../data/Scans\")]\n",
    "print(len(img_folders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at imaging data for a patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"patient\"])\n",
    "importlib.reload(sys.modules[\"read_scans_utils\"])\n",
    "import patient\n",
    "import read_scans_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict mapping patient id to data including: seriesnumber of AxialT2 scan, name of sequence,\n",
    "# expected number of slices by manual inspection using Slicer\n",
    "# Required for reading the axial T2w scans of the patients\n",
    "seriesnumber_dict = read_scans_utils.load_series_numbers_dict(\"../data/T2w_seriesnumber_info_Lucas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample patient\n",
    "patient7 = read_scans_utils.read_patient(\"MARPROC007_nii\", seriesnumbers_dict=seriesnumber_dict, print_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract & plot an axial T2 image\n",
    "axialt2_p7 = patient7.axialt2\n",
    "\n",
    "# Print the shape of the image\n",
    "# x, y, z, where x, y is the resolution of a single slice of the 3d image, and z the amount of slices\n",
    "print(np.asanyarray(axialt2_p7.dataobj).shape)\n",
    "# print the first slice in the image\n",
    "plt.imshow(np.asanyarray(axialt2_p7.dataobj)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adcmap_p7 = patient7.adcmap\n",
    "\n",
    "# ADC maps have a different resolution, and a different amount of slices per patient\n",
    "# For use in the training of a model, they will need to be resized to a common size\n",
    "print(np.asanyarray(adcmap_p7.dataobj).shape)\n",
    "\n",
    "# Plot adcmap image\n",
    "plt.imshow(np.asanyarray(adcmap_p7.dataobj[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perffrac_p7 = patient7.perfusionmap\n",
    "\n",
    "# Perfusion maps have the same resolution as ADC maps\n",
    "print(np.asanyarray(perffrac_p7.dataobj).shape)\n",
    "\n",
    "# Plot a perfusionmap image\n",
    "plt.imshow(np.asanyarray(perffrac_p7.dataobj[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the images are .nii or NifTi files, meaning they carry alot more metadata next to the actual imaging data\n",
    "print(patient7.axialt2)\n",
    "# print(patient7.adcmap)\n",
    "# print(patient7.perfusionmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking consistency across the whole set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the entire set will have to be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients, erroneous_patient_ids = read_scans_utils.read_patients(scans_data_path=\"../data/Scans\",\n",
    "                                          seriesnumber_info_path=\"../data/T2w_seriesnumber_info_Lucas.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to investigate how the resolutions of imaging differ between different patients the distribution of resolutions will be examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "t2_resolutions = defaultdict(int)\n",
    "adc_resolutions = defaultdict(int)\n",
    "perf_resolutions = defaultdict(int)\n",
    "\n",
    "for patient_id in patients:\n",
    "    patient = patients[patient_id]\n",
    "\n",
    "    t2_resolutions[np.asarray(patient.axialt2.dataobj).shape] += 1\n",
    "\n",
    "    adc_resolutions[np.asarray(patient.adcmap.dataobj).shape] += 1\n",
    "\n",
    "    perf_resolutions[np.asarray(patient.perfusionmap.dataobj).shape] += 1\n",
    "\n",
    "    \n",
    "\n",
    "df1 = pd.DataFrame(t2_resolutions.items(), columns = [\"Resolution\", \"Occurrences\"]).sort_values(\"Occurrences\", ascending = False)\n",
    "df2 = pd.DataFrame(adc_resolutions.items(), columns = [\"Resolution\", \"Occurrences\"]).sort_values(\"Occurrences\", ascending = False)\n",
    "df3 = pd.DataFrame(perf_resolutions.items(), columns = [\"Resolution\", \"Occurrences\"]).sort_values(\"Occurrences\", ascending = False)\n",
    "\n",
    "# read_scans_utils.display_side_by_side(df1, df2, df3)\n",
    "\n",
    "df1_styler = df1.style.set_table_attributes(\"style='display:inline'\").set_caption('T2 shapes')\n",
    "df2_styler = df2.style.set_table_attributes(\"style='display:inline'\").set_caption('ADC shapes')\n",
    "df3_styler = df3.style.set_table_attributes(\"style='display:inline'\").set_caption('Perfusion shapes')\n",
    "    \n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_()+df3_styler._repr_html_(), raw=True)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the scans have a consistent resolution, with slight variation in a part of the data.\n",
    "There are however some variations in either the resolution, the amount of slices, or both.\\\n",
    "Also important to note, is that the perfusion scans and adc scans overlap in their resolutions and slice amounts exactly, meaning the only thing that remains for scaling them for use in the network is to match them to their accompanying T2w scans together. \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check adc shape vs perffrac shape just to be sure\n",
    "for patient_id in patients:\n",
    "    patient = patients[patient_id]\n",
    "    adc = patient.get_adc_image_array()\n",
    "    perffrac = patient.get_perfusion_image_array()\n",
    "\n",
    "    if adc.shape != perffrac.shape:\n",
    "        print(\"DWI's dont match for \", patient_id)\n",
    "        print(\"adc shape      : \", adc.shape)\n",
    "        print(\"perfusion shape: \", perffrac.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing the DWI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes of array for patient7: \")\n",
    "patient7_t2 = patient7.get_axialt2_image_array()\n",
    "patient7_adc = patient7.get_adc_image_array()\n",
    "patient7_perffrac = patient7.get_perfusion_image_array()\n",
    "print(patient7_t2.shape)\n",
    "print(patient7_adc.shape)\n",
    "print(patient7_perffrac.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the shapes of the DWI's (176, 176, 20) need to be resized to match the T2 image (512, 512, 30) \\\n",
    "What the middle adc slice looks like before resizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient7_adc = patient7.get_adc_image_array()\n",
    "plt.imshow(patient7_adc[:, :, int(patient7_adc.shape[2]/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing using scipy's zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_factor = patient7_t2.shape[0]/patient7_adc.shape[0]\n",
    "z_factor = patient7_t2.shape[2]/patient7_adc.shape[2]\n",
    "\n",
    "new_image = zoom(patient7_adc, (x_y_factor, x_y_factor, z_factor))\n",
    "print(new_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the middle slice of the adc image looks like after resizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_image[:, :, int(new_image.shape[2]/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing using nilearn's resample_to_image\n",
    "This takes into account the affine matrix of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(patient7.adcmap)\n",
    "import nilearn.image as ni_im\n",
    "import os\n",
    "\n",
    "resampled_image = ni_im.resample_to_img(patient7.adcmap, patient7.axialt2)\n",
    "# nb.save(resampled_image, os.path.join(\".\", 'resampled_image.nii'))\n",
    "\n",
    "# resampled_image = ni_im.resample_to_img(patient7.adcmap, patient7.axialt2.affine)\n",
    "# print(patient7.axialt2.affine)\n",
    "# print(patient7.axialt2.shape)\n",
    "\n",
    "# resampled_image = ni_im.resample_img(patient7.adcmap, patient7.axialt2.affine, patient7.axialt2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_image.shape)\n",
    "# plt.imshow(resampled_image.dataobj[:, :, int(resampled_image.shape[2]/2)])\n",
    "plt.imshow(resampled_image.dataobj[:, :, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing using simpleitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(patient7.axialt2)\n",
    "\n",
    "patient7_sitk_t2 = sitk.ReadImage(\"../data/Scans/MARPROC007_nii/501_tt2_tse.nii\")\n",
    "axial7_array = sitk.GetArrayFromImage(patient7_sitk_t2)\n",
    "plt.imshow(axial7_array[int(axial7_array.shape[0]/2), :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient7_sitk_ADC = sitk.ReadImage(\"../data/Scans/MARPROC007_nii/899_tdwi_ssepi_801__20140825_adc.nii\")\n",
    "ADC_array = sitk.GetArrayFromImage(patient7_sitk_ADC)\n",
    "plt.imshow(ADC_array[int(ADC_array.shape[0]/2), :, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dimension = patient7_sitk_ADC.GetDimension()\n",
    "\n",
    "Transform = sitk.AffineTransform(Dimension)\n",
    "Transform.SetMatrix(patient7_sitk_ADC.GetDirection())\n",
    "Transform.SetTranslation(np.array(patient7_sitk_ADC.GetOrigin()) - patient7_sitk_t2.GetOrigin())\n",
    "\n",
    "ResImage = sitk.Resample(patient7_sitk_ADC, patient7_sitk_t2, Transform, sitk.sitkLinear, patient7_sitk_ADC.GetPixelIDValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ResImage.GetDimension())\n",
    "print(ResImage.GetSize())\n",
    "ResImage.GetSpacing()\n",
    "resampled_array = sitk.GetArrayFromImage(ResImage)\n",
    "plt.imshow(resampled_array[int(resampled_array.shape[0]/2), :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = sitk.ResampleImageFilter()\n",
    "resample.SetInterpolator = sitk.sitkLinear\n",
    "resample.SetOutputDirection = patient7_sitk_ADC.GetDirection()\n",
    "resample.SetOutputOrigin = patient7_sitk_ADC.GetOrigin()\n",
    "new_spacing = [1, 1, 1]\n",
    "print(new_spacing)\n",
    "resample.SetOutputSpacing(new_spacing)\n",
    "# new_spacing = np.array(new_spacing)\n",
    "\n",
    "orig_size = np.array(patient7_sitk_ADC.GetSize(), dtype=np.int64)\n",
    "orig_spacing = np.array([x for x in patient7_sitk_ADC.GetSpacing()])\n",
    "print(orig_spacing)\n",
    "new_size = orig_size*(orig_spacing/new_spacing)\n",
    "new_size = np.ceil(new_size).astype(np.int64) #  Image dimensions are in integers\n",
    "new_size = [int(s) for s in new_size]\n",
    "print(new_size)\n",
    "resample.SetSize(new_size)\n",
    "\n",
    "newimage = resample.Execute(patient7_sitk_ADC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_array = sitk.GetArrayFromImage(newimage)\n",
    "plt.imshow(resampled_array[int(resampled_array.shape[0]/2), :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the delineation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"patient\"])\n",
    "importlib.reload(sys.modules[\"read_scans_utils\"])\n",
    "import patient\n",
    "import read_scans_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads delineations in the format: {patient_id: [(name_of_file, [array, metadata])\n",
    "#                                                 (name_of_file, ......           )\n",
    "#                                                ]\n",
    "#                                   }\n",
    "delineations = read_scans_utils.read_delineations()\n",
    "\n",
    "print(len(delineations))\n",
    "print(len(delineations[\"MARPROC007\"]))\n",
    "print([x[0] for x in delineations[\"MARPROC007\"]])\n",
    "print(delineations[\"MARPROC007\"][0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(delineations[\"MARPROC007\"][1][1][1]))\n",
    "print(delineations[\"MARPROC007\"][1][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername_delins = \"../data/Regions ground truth/Regions delineations/\"\n",
    "\n",
    "delin_folders = [f for f in listdir(foldername_delins)]\n",
    "print(\"Amount of patient folders included in the dataset: \", len(delin_folders))\n",
    "\n",
    "delineations_counts = defaultdict(int)\n",
    "patients_to_skip = {x for x in erroneous_patient_ids}\n",
    "print(patients_to_skip)\n",
    "\n",
    "# Count the amount of delineation files per patient to see what is the distribution of file counts\n",
    "for patient_id, patient_delineations in delineations.items():\n",
    "    if patient_id in patients_to_skip:\n",
    "        continue\n",
    "    \n",
    "    delineations_counts[(len(patient_delineations))] += 1\n",
    "\n",
    "\n",
    "del_counts_df = pd.DataFrame(delineations_counts.items(), columns = [\"Amount of delineations\", \"count\"]).sort_values(\"count\", ascending=False)\n",
    "display(del_counts_df)\n",
    "print(del_counts_df[\"count\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most patients have 2 delineation files. There are a few outliers with 5 and even 6 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient = None\n",
    "# delineation = None\n",
    "\n",
    "# print(\"Delineations for single patients: \")\n",
    "# i = 0\n",
    "# for patient_id, delineations_patient in delineations.items():\n",
    "#     print(patient_id, [delineations_patient[i][0] for i in range(len(delineations_patient))])\n",
    "#     i += 1\n",
    "#     if i > 4:\n",
    "#         break\n",
    "\n",
    "\n",
    "# nrrd_delineations = delineations[\"MARPROC007\"]\n",
    "# nrrd_delineations2 = delineations[\"MARPROC343\"]\n",
    "# print(\"\\nDelineation data for a single patient:\")\n",
    "# print(nrrd_delineations[0][0])\n",
    "# print(nrrd_delineations[0][1][0].shape)\n",
    "# print(nrrd_delineations[0][1][1])\n",
    "# print()\n",
    "# print(nrrd_delineations2[0][0])\n",
    "# print(nrrd_delineations2[0][1][0].shape)\n",
    "# print(nrrd_delineations2[0][1][1])\n",
    "\n",
    "\n",
    "# patient_6files = delineations[\"MARPROC204\"]\n",
    "# print(\"\\nThe files in the folder of the patient with the most files (6):\")\n",
    "# print([patient_6files[i][0] for i in range(len(patient_6files))])\n",
    "\n",
    "# # Printing 2 files for patient 204 of different zones for GG3 regions\n",
    "# # They should match in resolution\n",
    "# print(\"\\nResolution of GG3 in TZ and GG3 in PZ of patient 204:\")\n",
    "# patient_204_delins = delineations[\"MARPROC204\"]\n",
    "# for delin in patient_204_delins:\n",
    "#     if \"GG3\" in delin[0]:\n",
    "#         print(delin[0])\n",
    "#         print(delin[1][0].shape, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients have a combination of files representing regions of differing GG tissue. Also, as visible from the patient with the most delineation files available across all patients multiple files are available for even a single GG. This means that the tumor that is delineated for this patient, and its GG regions, cover the two different zones of the prostate: the peripheral zone (PZ) and the transition zone (TZ). For this research the seperation between zones is not relevant, so these will be combined. As visible above in this case they share resolution, since they are both still registered to the entire T2 scan. A total GG3 region delineation will be formed by performing an OR operation of the files for both zones.\n",
    "As visible the delineation, when opened using pynrrd consists of a 3d image in the form of a 3d numerical array, matching the resolution of the T2 axial image loaded earlier. Also some metadata is included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the distribution of resolutions of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delin_resolutions = defaultdict(int)\n",
    "\n",
    "for patient_id, delineations_patient in delineations.items():\n",
    "    shapes = set()\n",
    "\n",
    "    for delineation in delineations_patient:\n",
    "        shapes.add(delineation[1][0].shape)\n",
    "    if len(shapes) == 1:\n",
    "        delin_resolutions[shapes.pop()] += 1\n",
    "\n",
    "\n",
    "delin_resolutions_df = pd.DataFrame(delin_resolutions.items(), columns=[\"resolution\", \"count\"])\n",
    "display(delin_resolutions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The delineations seem to contain some differing resolutions as there are more unique resolutions (20) than the amount of resolutions in the T2 axial scans (14). Some additional checks will have to be done when adding the delineations to the patients to ensure they match T2 resolution. As of now it is not yet completely clear how to represent the delineations within a patient or slice so the reading will be performed later (this is also not necessary for the EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_1_delineations = delineations[\"MARPROC007\"]\n",
    "\n",
    "# iterate over slices\n",
    "delineated_slices = []\n",
    "print(patient_1_delineations[0][0])\n",
    "for i, slice in enumerate(np.rollaxis(patient_1_delineations[0][1][0], 2)):\n",
    "    if 1 in slice:\n",
    "        delineated_slices.append(i)\n",
    "\n",
    "print(\"\\nSlices that contain a delineation: \")\n",
    "print(delineated_slices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking in how many cases the shape of the delineation of a patient matches the loaded axial t2 of that patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_delin_patients = set()\n",
    "\n",
    "for patient_id, delineations_patient in delineations.items():\n",
    "    delineations_shape_patient = delineations_patient[0][1][0].shape\n",
    "\n",
    "    if patient_id in patients:\n",
    "        t2_shape_patient = patients[patient_id].get_axialt2_image_array().shape\n",
    "\n",
    "        if delineations_shape_patient != t2_shape_patient:\n",
    "            bad_delin_patients.add(patient_id)\n",
    "            print(patient_id, \": Shape of delineations and t2 doesnt match\")\n",
    "            print(\"dimensions of delineations: \", delineations_shape_patient)\n",
    "            print(\"Axialt2 of patient:         \", t2_shape_patient)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARPROC343 seems to have a weirdly transposed shape\n",
    "# The amount of slices doesnt match however, so just leave it.\n",
    "# tft_delin = delineations[\"MARPROC343\"]\n",
    "# tft = patients[\"MARPROC343\"]\n",
    "# print(tft_delin[0][1][0].shape)\n",
    "# print(tft.get_axialt2_image_array().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to add the delineations to the patient objects\n",
    "Each Patient will get a single 3d array representing the map of all the Gleason Pattern regions together. In this map for each voxel, 0 represents healthy tissue, 1 represents GG3, 2 represents GG4 and 3 represents Cribriform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"patient\"])\n",
    "importlib.reload(sys.modules[\"read_scans_utils\"])\n",
    "import patient\n",
    "from patient import Patient\n",
    "import read_scans_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_scans_utils.combine_patients_delineations(patients, delineations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patient.show_patient_delineation_slices(patients[\"MARPROC007\"])\n",
    "print()\n",
    "# Patient.show_patient_delineation_slices(patients[\"MARPROC204\"])\n",
    "\n",
    "# print([delineation[0] for delineation in delineations[\"MARPROC204\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check MARPROC204, the patient with 6 delineation files\n",
    "delineated_slices_gg3 = []\n",
    "delineated_slices_gg4 = []\n",
    "delineated_slices_Cribriform = []\n",
    "\n",
    "# for i, slice in enumerate(np.rollaxis(patients[\"MARPROC204\"].region_delineation, 2)):\n",
    "for i, slice in enumerate(np.rollaxis(patients[\"MARPROC007\"].region_delineation, 2)):\n",
    "    if 1 in slice:\n",
    "        delineated_slices_gg3.append(i)\n",
    "    if 2 in slice:\n",
    "        delineated_slices_gg4.append(i)\n",
    "    if 3 in slice:\n",
    "        delineated_slices_Cribriform.append(i)\n",
    "\n",
    "print(delineated_slices_gg3)\n",
    "print(delineated_slices_gg4)\n",
    "print(delineated_slices_Cribriform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting slices from patients based on if they have a delineation available\n",
    "Not all slices have delineations associated with them. Slices that don't, lack ground truth, since the lack of a delineation does not signify the absence of cancerous tissue. Thus only the slices that have ground truth are usable for model training. For every patient, the slices, and the numbers/indexes of the slices in segmentation that have a delineation will be collected. The indexes will then be used to collect associated slices from the other images of that patient. This will result in a number of quadruples per patient, consisting of a triple of slices for each of the input modalities (T2, ADC & perfusion) and a segmentation slice. These will form the input for the model.\n",
    "\n",
    "The model expects a 3d image per patient per modality, so for each patient a 3d image of those aforementioned slices will be created (resulting in 4 images including the segmentation). This will be a subset of the complete image of that modality. nnUNet will train slice-wise using these, meaning it will take single slices across modalities (the quadruples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nibabel.spatialimages import SpatialFirstSlicer\n",
    "test = SpatialFirstSlicer(patients[\"MARPROC007\"].adcmap)\n",
    "# print(test)\n",
    "# print(test.shape)\n",
    "\n",
    "hoi = test[:, :, 5:10]\n",
    "print(hoi)\n",
    "print(hoi.shape)\n",
    "print(hoi.get_fdata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hoi.get_fdata()[:, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_scans_utils.resize_dwis(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[\"MARPROC007\"].extract_slice_tuples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring sitk, a commong library for working with multidimensional and multimodal medical imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asanyarray(perffrac_p7.dataobj[:, :, 0]))\n",
    "print(np.asanyarray(perffrac_p7.dataobj[:, :, 0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_perf = sitk.GetImageFromArray(np.asanyarray(perffrac_p7.dataobj))\n",
    "img_adc = sitk.GetImageFromArray(np.asanyarray(adcmap_p7.dataobj))\n",
    "# img_perf.GetSize()\n",
    "# img_perf.GetDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "slice = sitk.GetArrayViewFromImage(img_perf)[:, :, z]\n",
    "plt.imshow(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myshow(img):\n",
    "    nda = sitk.GetArrayViewFromImage(img)\n",
    "    plt.imshow(nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have no idea what this does\n",
    "myshow(img_perf[0, :, :] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible image blending\n",
    "simpleitk also contains functionality to blend segmentations with images (or contours of segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image_multiply(mask, image):\n",
    "    components_per_pixel = image.GetNumberOfComponentsPerPixel()\n",
    "    if components_per_pixel == 1:\n",
    "        return mask * image\n",
    "    else:\n",
    "        return sitk.Compose(\n",
    "            [\n",
    "                mask * sitk.VectorIndexSelectionCast(image, channel)\n",
    "                for channel in range(components_per_pixel)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "def alpha_blend(image1, image2, alpha=0.5, mask1=None, mask2=None):\n",
    "    \"\"\"\n",
    "    Alaph blend two images, pixels can be scalars or vectors.\n",
    "    The alpha blending factor can be either a scalar or an image whose\n",
    "    pixel type is sitkFloat32 and values are in [0,1].\n",
    "    The region that is alpha blended is controled by the given masks.\n",
    "    \"\"\"\n",
    "\n",
    "    if not mask1:\n",
    "        mask1 = sitk.Image(image1.GetSize(), sitk.sitkFloat32) + 1.0\n",
    "        mask1.CopyInformation(image1)\n",
    "    else:\n",
    "        mask1 = sitk.Cast(mask1, sitk.sitkFloat32)\n",
    "    if not mask2:\n",
    "        mask2 = sitk.Image(image2.GetSize(), sitk.sitkFloat32) + 1\n",
    "        mask2.CopyInformation(image2)\n",
    "    else:\n",
    "        mask2 = sitk.Cast(mask2, sitk.sitkFloat32)\n",
    "    # if we received a scalar, convert it to an image\n",
    "    if type(alpha) != sitk.SimpleITK.Image:\n",
    "        alpha = sitk.Image(image1.GetSize(), sitk.sitkFloat32) + alpha\n",
    "        alpha.CopyInformation(image1)\n",
    "    components_per_pixel = image1.GetNumberOfComponentsPerPixel()\n",
    "    if components_per_pixel > 1:\n",
    "        img1 = sitk.Cast(image1, sitk.sitkVectorFloat32)\n",
    "        img2 = sitk.Cast(image2, sitk.sitkVectorFloat32)\n",
    "    else:\n",
    "        img1 = sitk.Cast(image1, sitk.sitkFloat32)\n",
    "        img2 = sitk.Cast(image2, sitk.sitkFloat32)\n",
    "\n",
    "    intersection_mask = mask1 * mask2\n",
    "\n",
    "    intersection_image = mask_image_multiply(\n",
    "        alpha * intersection_mask, img1\n",
    "    ) + mask_image_multiply((1 - alpha) * intersection_mask, img2)\n",
    "    return (\n",
    "        intersection_image\n",
    "        + mask_image_multiply(mask2 - intersection_mask, img2)\n",
    "        + mask_image_multiply(mask1 - intersection_mask, img1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = (alpha_blend(img_perf, img_adc), \"alpha_blend_standard\")\n",
    "\n",
    "myshow(blend[0][0, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myshow(img_perf[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myshow(img_adc[0, :, :])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
