{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_val = \"validation\"\n",
    "# test_or_val = \"test\"\n",
    "\n",
    "datafolder = f\"./contours_compare_{test_or_val}\"\n",
    "\n",
    "root, dirs, files = next(os.walk(f\"{datafolder}\"))\n",
    "for i, dir in enumerate(dirs):\n",
    "    print(f\"{i}: {dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_number = 1\n",
    "\n",
    "dataset = dirs[set_number]\n",
    "dataset_path = f\"{datafolder}/{dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"{dataset_path}/summary.json\") as f:\n",
    "        output_statistics = json.load(f)\n",
    "except:\n",
    "    print(f\"{dataset} doesn't have a summary json. Aborting...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a range of dice thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper functions to calculate metrics of the case of a single dice threshold \\\n",
    "metric used is F1-score \n",
    "\n",
    "$\\frac{2tp}{2tp + fp + fn}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(dict_with_cm):\n",
    "    TP, FP, TN, FN = dict_with_cm[\"TP\"], dict_with_cm[\"FP\"], dict_with_cm[\"TN\"], dict_with_cm[\"FN\"]\n",
    "\n",
    "    score = 2 * TP / (2 * TP + FP + FN)\n",
    "    return score\n",
    "\n",
    "def sensitivity(dict_with_cm):\n",
    "    TP, FP, TN, FN = dict_with_cm[\"TP\"], dict_with_cm[\"FP\"], dict_with_cm[\"TN\"], dict_with_cm[\"FN\"]\n",
    "\n",
    "    score = TP / (TP + FN)\n",
    "    return score\n",
    "\n",
    "def specificity(dict_with_cm):\n",
    "    TP, FP, TN, FN = dict_with_cm[\"TP\"], dict_with_cm[\"FP\"], dict_with_cm[\"TN\"], dict_with_cm[\"FN\"]\n",
    "    print(FP, TN)\n",
    "    score = TN / (TN + FP)\n",
    "    return score\n",
    "\n",
    "# Determine dice score of segmentation wrt ground truth\n",
    "# regions to calculate dice score of are expected to be labeled with 1\n",
    "def dice(gt, seg):\n",
    "    label = 1\n",
    "    twice_the_intersection = np.sum(np.where(seg == label, 1, 0)[gt == label]) * 2.0\n",
    "    sum_of_volumes = np.sum(seg) + np.sum(gt)\n",
    "\n",
    "    return twice_the_intersection / sum_of_volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_thresholds = np.arange(0.025, 0.91, 0.025)\n",
    "print(dice_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg3_f1_scores = []\n",
    "gg4_f1_scores = []\n",
    "cribriform_f1_scores = []\n",
    "foreground_f1_scores = []\n",
    "\n",
    "path_to_gt = f\"{dataset_path}/ground_truth\"\n",
    "path_to_mp = f\"{dataset_path}/model_output\"\n",
    "\n",
    "\n",
    "# The evaluation of model output statistics\n",
    "###############\n",
    "# get_avg_dice_score = lambda stats_dicts: {label: stats_dicts[label][\"tp_dice_scores_sum\"]/stats_dicts[label][\"TP\"]  if stats_dicts[label][\"TP\"] != 0 else 0 for label in stats_dicts.keys()}\n",
    "\n",
    "i = 0\n",
    "\n",
    "# for dice_threshold in tqdm(dice_thresholds[0:1]):\n",
    "for dice_threshold in tqdm(dice_thresholds):\n",
    "    stats_dicts = {label:\n",
    "                    {\n",
    "                        \"TP\": 0,\n",
    "                        \"FP\": 0,\n",
    "                        \"TN\": 0,\n",
    "                        \"FN\": 0,\n",
    "                    }\n",
    "                    for label in [1, 2, 3, 4]\n",
    "                }\n",
    "\n",
    "    for i, patient_filename in enumerate(os.listdir(path_to_gt)):        \n",
    "        gt_array = sitk.GetArrayFromImage(sitk.ReadImage(f\"{path_to_gt}/{patient_filename}\"))\n",
    "        mp_array = sitk.GetArrayFromImage(sitk.ReadImage(f\"{path_to_mp}/{patient_filename}\"))\n",
    "\n",
    "        # For every label except background, consider only regions of that label and decide\n",
    "        # on confusion metric and/or dice score for those regions\n",
    "        for label in [1, 2, 3]:\n",
    "            label_only_gt = np.where(gt_array == int(label), 1, 0)\n",
    "            label_only_seg = np.where(mp_array == int(label), 1, 0)\n",
    "\n",
    "            if np.all(label_only_gt == 0) and np.all(label_only_seg == 0):\n",
    "                stats_dicts[label][\"TN\"] += 1\n",
    "            elif np.all(label_only_gt == 0) and not np.all(label_only_seg == 0):\n",
    "                stats_dicts[label][\"FP\"] += 1\n",
    "            elif not np.all(label_only_gt == 0) and np.all(label_only_seg == 0):\n",
    "                stats_dicts[label][\"FN\"] += 1\n",
    "            else:\n",
    "                dice_score = dice(label_only_gt, label_only_seg)\n",
    "\n",
    "                if dice_score > dice_threshold:\n",
    "                    stats_dicts[label][\"TP\"] += 1\n",
    "                else:\n",
    "                    stats_dicts[label][\"FN\"] += 1\n",
    "\n",
    "        # Now do the same one more time, but without distinguishing between the different\n",
    "        # patterns, so only for foreground vs background.\n",
    "        simplified_gt_array = np.where(gt_array != 0, 1, 0)\n",
    "        simplified_mp_array = np.where(mp_array != 0, 1, 0)\n",
    "\n",
    "        if np.all(simplified_gt_array == 0) and np.all(simplified_mp_array == 0):\n",
    "            stats_dicts[4][\"TN\"]\n",
    "        elif np.all(simplified_gt_array == 0) and not np.all(simplified_mp_array == 0):\n",
    "            stats_dicts[4][\"FP\"]\n",
    "        elif not np.all(simplified_gt_array == 0) and np.all(simplified_mp_array == 0):\n",
    "            stats_dicts[4][\"FN\"]\n",
    "        else:\n",
    "            dice_score = dice(simplified_gt_array, simplified_mp_array)\n",
    "\n",
    "            if dice_score > dice_threshold:\n",
    "                stats_dicts[label][\"TP\"] += 1\n",
    "            else:\n",
    "                stats_dicts[label][\"FN\"] += 1\n",
    "\n",
    "    print(stats_dicts)\n",
    "    # Saving this resulting f1_scores\n",
    "    for label in stats_dicts.keys():\n",
    "        print(f\"{label} : {f1_score(stats_dicts[label])}\")\n",
    "\n",
    "        if label == 1:\n",
    "            gg3_f1_scores.append(f1_score(stats_dicts[label]))\n",
    "        elif label == 2:\n",
    "            gg4_f1_scores.append(f1_score(stats_dicts[label]))\n",
    "        elif label == 3:\n",
    "            cribriform_f1_scores.append(f1_score(stats_dicts[label]))\n",
    "        elif label == 4:\n",
    "            foreground_f1_scores.append(f1_score(stats_dicts[label]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_f1scores = {\n",
    "    \"dice_thresholds\": [round(threshold, 4) for threshold in dice_thresholds],\n",
    "    \"GG3\": gg3_f1_scores,\n",
    "    \"GG4\": gg4_f1_scores,\n",
    "    \"Cribriform\": cribriform_f1_scores\n",
    "}\n",
    "\n",
    "with open(f\"{dataset_path}/{dataset}_f1scores.json\", 'w', encoding = 'utf-8') as f:\n",
    "    json.dump(dataset_f1scores, f, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg3_f1_scores[0] = 0.6129032258064516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gg3_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gg3_f1_scores)\n",
    "print(gg4_f1_scores)\n",
    "print(cribriform_f1_scores)\n",
    "# print(foreground_background_f1_scores)\n",
    "\n",
    "# print(gg3_f1_scores[3])\n",
    "# print(gg4_f1_scores[3])\n",
    "# print(cribriform_f1_scores[3])\n",
    "# print(foreground_background_f1_scores[3])\n",
    "test[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_005_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=12)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=24)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "plt.rc('figure', titlesize=16)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize = (7, 6))\n",
    "\n",
    "sns.lineplot(x = dice_thresholds, y = gg3_f1_scores, ax = axis, label = \"GG3\")\n",
    "sns.lineplot(x = dice_thresholds, y = gg4_f1_scores, ax = axis, label = \"GG4\")\n",
    "sns.lineplot(x = dice_thresholds, y = cribriform_f1_scores, ax = axis, label = \"Cribriform\")\n",
    "# if SIMPLIFIED_DATASET:\n",
    "#     sns.lineplot(x = dice_thresholds, y = foreground_background_f1_scores, ax = axis, label = \"Foreground\")\n",
    "\n",
    "plt.axvline(0.1, color = \"red\", linestyle = \"dashed\", linewidth = 1, label = \"Dice == 0.1\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dice threshold\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "\n",
    "\n",
    "plt.title(f\"F1-scores for region detection\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_thresholds.index(0.1)\n",
    "\n",
    "index_of_usual_threshold = np.where(dice_thresholds == 0.1)[0][0]\n",
    "\n",
    "print(gg3_f1_scores[index_of_usual_threshold])\n",
    "print(gg4_f1_scores[index_of_usual_threshold])\n",
    "print(cribriform_f1_scores[index_of_usual_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "sns.lineplot(x = dice_thresholds, y = gg3_sensitivity_scores, ax = axis, label = \"GG3 sensitivity\")\n",
    "sns.lineplot(x = dice_thresholds, y = gg4_sensitivity_scores, ax = axis, label = \"GG4 sensitivity\")\n",
    "sns.lineplot(x = dice_thresholds, y = cribriform_sensitivity_scores, ax = axis, label = \"Cribriform sensitivity\")\n",
    "\n",
    "sns.lineplot(x = dice_thresholds, y = gg3_specificity_scores, ax = axis, label = \"GG3 specificity\")\n",
    "sns.lineplot(x = dice_thresholds, y = gg4_specificity_scores, ax = axis, label = \"GG4 specificity\")\n",
    "sns.lineplot(x = dice_thresholds, y = cribriform_specificity_scores, ax = axis, label = \"Cribriform specificity\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dice threshold\")\n",
    "plt.ylabel(\"Value of metric\")\n",
    "plt.title(f\"All-modalities dataset sensitivity and specificity for different TP-thresholds of Volumetric Dice score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(os.listdir(path_to_simplified_gt)))\n",
    "# print(len(foreground_background_dices))\n",
    "# print(len(data))\n",
    "# data.loc[16]\n",
    "# # for dice in foreground_background_dices:\n",
    "# #     print(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fgbg_dices\"] = foreground_background_dices[:42]\n",
    "data[['filename','structure', 'volumetric_dice', 'fgbg_dices']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_imgs = f\"../../exploratory-data-analysis\"\n",
    "all_modalities_fig = plt.imread(f\"{path_to_imgs}/region_detection_f1_scores_allmodalities.png\")\n",
    "t2adc_fig = plt.imread(f\"{path_to_imgs}/region_detection_f1_scores_t2_adc.png\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 10))\n",
    "plt.xticks(None)\n",
    "axs[0].imshow(all_modalities_fig)\n",
    "axs[1].imshow(t2adc_fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
